{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tensorboard\n",
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CME and CLE parameters\n",
    "concA = 10\n",
    "concB = 20\n",
    "k1 = 6\n",
    "k2 = 1.0\n",
    "k3 = 230\n",
    "k4 = 1000\n",
    "vol = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define intensity functions\n",
    "def lambda1(n):\n",
    "    return concA*k1*n*(n-1)/vol\n",
    "def lambda2(n):\n",
    "    return k2*n*(n-1)*(n-2)/vol**2\n",
    "def lambda3(n):\n",
    "    return concB*k3*vol\n",
    "def lambda4(n):\n",
    "    return  n*k4\n",
    "\n",
    "# Define terminal condition function\n",
    "def terminalCondition(n):\n",
    "    return 1.0*n\n",
    "\n",
    "# Define drift and diffusion coefficients\n",
    "def drift(x):\n",
    "    return lambda1(x) - lambda2(x) + lambda3(x) - lambda4(x)\n",
    "\n",
    "def diffusion(x):\n",
    "    sigma = []\n",
    "    for i in range(len(x)):\n",
    "        sigma.append([np.sqrt(lambda1(x[i])), - np.sqrt(lambda2(x[i])), \n",
    "                      np.sqrt(lambda3(x[i])), -np.sqrt(lambda4(x[i]))])\n",
    "    return np.array(sigma, dtype=np.float32)\n",
    "\n",
    "def diffusiontf(x):\n",
    "    sigma = [np.sqrt(lambda1(x)), - np.sqrt(lambda2(x)), \n",
    "             np.sqrt(lambda3(x)), -np.sqrt(lambda4(x))]\n",
    "    return tf.convert_to_tensor(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "dt = 0.0001\n",
    "nreactions = 4\n",
    "timesteps = 10\n",
    "\n",
    "# Network parameters\n",
    "inputSize = timesteps*(nreactions + 1) + 1\n",
    "hlayer_depth = 4\n",
    "hlayer_width = inputSize + 10\n",
    "activation_func = tf.nn.relu \n",
    "initialLearningRate = 1e-2 #1e-3 \n",
    "trainingIterations = 5000 \n",
    "batchSize   = 64 #512\n",
    "\n",
    "# Domain parameters\n",
    "domain = [50,500]\n",
    "outputResolution = 200\n",
    "\n",
    "\n",
    "# File writing parameters\n",
    "datasize = 1024*5\n",
    "stride = 10\n",
    "#filename = \"data/schlogl_data_bckwd_v\" + str(vol)\"_\" + str(datasize) + \"_T=\" + str(timesteps*dt) + \".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Brownian paths function\n",
    "def generateBrownian(n):\n",
    "    output = np.zeros([n,4])\n",
    "    for i in range(n):\n",
    "        output[i] = np.random.normal(0., np.sqrt(dt), nreactions)\n",
    "    return output\n",
    "\n",
    "# Propagate forward SDE function\n",
    "def propagateSDE(x0, brownianPath):\n",
    "    n = len(brownianPath)\n",
    "    dimension = len(x0)\n",
    "    trajectory = np.zeros([n, dimension])\n",
    "    trajectory[0] = 1.0*x0\n",
    "    for i in range(n-1):\n",
    "        x = trajectory[i]\n",
    "        trajectory[i+1] = x + drift(x)*dt + np.dot(diffusion(x),brownianPath[i])\n",
    "        if trajectory[i+1] < 0:\n",
    "            trajectory[i+1] = 0\n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate network structure, see paper\n",
    "\n",
    "# Inputs and targets placeholders for trained data\n",
    "networkInput = tf.placeholder(dtype=tf.float32, shape=(None, inputSize), name='input')\n",
    "networkTarget = tf.placeholder(dtype=tf.float32, shape=(None, 1), name='target')\n",
    "#networkTarget = tf.placeholder(dtype=tf.float32, shape=(None, timesteps + 1), name='target')\n",
    "\n",
    "# Set second part of input into brownian  paths tensor\n",
    "brownianPaths = (timesteps)*[None]\n",
    "for k in range(timesteps):\n",
    "    brownianPaths[k] = networkInput[:,timesteps + 1 + k*nreactions : timesteps + 1 + k*nreactions + nreactions]\n",
    "\n",
    "# Create hidden layers, hidden[timestep][hlayer_depth]\n",
    "hidden = [[None for i in range(hlayer_depth-1)] for j in range(timesteps)] \n",
    "for k in range(timesteps):\n",
    "    # Set input of each hidden layer to X_tk (first part of input vector)\n",
    "    hidden[k][0] = networkInput[:, k:k+1]\n",
    "    # Connect the hidden layers for each timestep\n",
    "    for i in range(hlayer_depth-2):\n",
    "        hidden[k][i+1] = tf.layers.dense(hidden[k][i], hlayer_width, activation=activation_func, \n",
    "                                         name='hidden' + str(k) + '-' + str(i+1))\n",
    "        \n",
    "# Set output of hidden layers to be the gradients (note index doesnt match hidden layer index due to initial value)\n",
    "gradients = (timesteps+1)*[None]\n",
    "gradients[0] = tf.Variable(0.5, dtype=tf.float32, name='gradient0') # Initial value at X0\n",
    "for k in range(timesteps):\n",
    "    gradients[k+1] = tf.layers.dense(hidden[k][hlayer_depth-2], 1, activation=None, name='gradient' + str(k+1))\n",
    "\n",
    "# Connect gradients to Euler Maruyama scheme\n",
    "predictions = (timesteps + 1)*[None]\n",
    "predictions[0] = tf.Variable(120.0, dtype=tf.float32, name='prediction0') # Initial value at X0\n",
    "sigma = (timesteps)*[None]\n",
    "noiseterm = (timesteps)*[None]\n",
    "for k in range(timesteps):\n",
    "    sigma[k] = tf.py_func(diffusion, [hidden[k][0]], tf.float32)\n",
    "    noiseterm[k] = tf.matmul(tf.reshape(sigma[k], [-1,nreactions]) , \n",
    "                             tf.reshape(brownianPaths[k], [-1, nreactions]),\n",
    "                            transpose_b = True)\n",
    "    predictions[k+1] = predictions[k] + gradients[k]*noiseterm[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training procedure\n",
    "\n",
    "# Define loss function and error\n",
    "loss = tf.reduce_mean(tf.square(predictions[-1] - networkTarget))\n",
    "error = tf.reduce_max(tf.abs(predictions[-1] - networkTarget))\n",
    "\n",
    "# use stochastic gradient descent with ADAM during optimization\n",
    "step = tf.train.AdamOptimizer(initialLearningRate).minimize(loss)\n",
    "\n",
    "# For tensor board\n",
    "mse_summary = tf.summary.scalar('Error', error)\n",
    "file_writer = tf.summary.FileWriter(logdir,\ttf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Training data\n",
    "generateData = True\n",
    "    \n",
    "if generateData:\n",
    "    #x0 = np.float32((domain[1] - domain[0])*np.random.rand(datasize) + domain[0])\n",
    "    x0 = np.float32((domain[1]-domain[0])/2.0)\n",
    "    \n",
    "    num_cores = multiprocessing.cpu_count() \n",
    "    brownianTrajs = Parallel(n_jobs=num_cores, \n",
    "                             verbose = 2)(delayed(generateBrownian)(timesteps) for i in range(datasize))\n",
    "    solutionsSDE = Parallel(n_jobs=num_cores, \n",
    "                            verbose = 2)(delayed(propagateSDE)(np.array([x0]),brownianTrajs[i]) for i in range(datasize))\n",
    "    # No need to write to file\n",
    "    #print(\"Writing to file ...\", end=\"\\r\")\n",
    "    #f = open(filename,\"w\")\n",
    "    #for i in range(len(results)):\n",
    "    #    f.write(\" \".join(str(x) for x in results[i]) + \"\\n\")\n",
    "    #f.close()\n",
    "    #print(\"Percentage finished:\", 100, \"%    \", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and target data\n",
    "inputData = [None]*datasize\n",
    "targetData = [None]*datasize\n",
    "for i in range(datasize):\n",
    "    flattBrownianTrajs = np.reshape(brownianTrajs[i], [-1,1])\n",
    "    flattX0 = np.reshape(np.array([x0]), [-1,1])\n",
    "    inputData[i] = np.concatenate((flattX0, solutionsSDE[i], flattBrownianTrajs))\n",
    "    targetData[i] = terminalCondition(solutionsSDE[i][-1])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Tensorflow session and initialize all network variables\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices =  np.random.randint(0, datasize, batchSize)\n",
    "inputBatch = np.reshape(np.take(inputData, indices, axis = 0), [-1, inputSize])\n",
    "targetBatch = np.reshape(np.take(np.array(targetData), indices,), [-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training\n",
    "\n",
    "# run gradient descent steps with Adam\n",
    "print('\\nStarted training...')\n",
    "print('{:8s}\\t{:8s}\\t{:8s}'.format('iter', 'l2-loss', 'linf-err'))\n",
    "print('{:8s}\\t{:8s}\\t{:8s}'.format(*(3*[8*'-'])))\n",
    "for iter in range(trainingIterations):\n",
    "    # generate random batch of inputs and corresponding target values\n",
    "    indices =  np.random.randint(0, datasize, batchSize)\n",
    "    inputBatch = np.reshape(np.take(inputData, indices, axis = 0), [-1, inputSize])\n",
    "    targetBatch = np.reshape(np.take(np.array(targetData), indices), [-1,1])\n",
    "\n",
    "    # take gradient descent step and compute loss & error\n",
    "    loss_val, error_val, _ = session.run(\n",
    "        [loss, error, step],\n",
    "        feed_dict={networkInput: inputBatch, \n",
    "                   networkTarget: targetBatch}\n",
    "    )\n",
    "    if iter % 100 == 0:\n",
    "        print('{:8d}\\t{:1.2e}\\t{:1.2e}'.format(iter, loss_val, error_val))\n",
    "print('...finished training.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tensor board\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(session.run(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = np.float32((domain[1]-domain[0])/2.0)\n",
    "dWs = generateBrownian(timesteps)\n",
    "solutionSDE = propagateSDE(np.array([x0]), dWs)\n",
    "fdWs = np.reshape(dWs, [-1,1])\n",
    "fx0 = np.reshape(np.array([x0]), [-1,1])\n",
    "input_test = np.concatenate((fx0, solutionSDE, fdWs))\n",
    "input_test = np.reshape(input_test, [-1, inputSize])\n",
    "result = session.run( gradients[0], feed_dict={networkInput: input_test})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(targetData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.constant([7, 8, 9, 10, 11, 12], shape=[6, 1])\n",
    "func = tf.py_func(diffusion, [a], tf.float32)\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    #a.initializer.run()\n",
    "    #func.initializer.run()\n",
    "    result=func.eval()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = tf.constant([1,2,3,4,5,6,7,8,9,10,11,12], dtype=tf.float32)\n",
    "#inp = tf.reshape(inp, shape=[-1,4])\n",
    "sigma1 = tf.py_func(diffusion, [inp], tf.float32)\n",
    "sigma2 = tf.reshape(sigma1, [-1,nreactions])\n",
    "\n",
    "inp2 = tf.constant([10,20,30,40,50,60,70,80,90,100,110,120], dtype=tf.float32)\n",
    "bps=3*[None]\n",
    "\n",
    "for k in range(3):\n",
    "    bps[k] = inp2[k*nreactions : k*nreactions + nreactions]\n",
    "bps2 = tf.reshape(bps, [-1, nreactions])\n",
    "matmul = tf.matmul(sigma2,bps2, transpose_b=True)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    result=sigma2.eval()\n",
    "    result2 = bps2.eval()\n",
    "    result3 = matmul.eval()\n",
    "print(result,result2.transpose(),result3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
