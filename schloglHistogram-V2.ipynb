{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from main.schlogModel import schloglModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Schlogl model\n",
    "smodel = schloglModel()\n",
    "\n",
    "# Define and set parameters\n",
    "concA = 10.\n",
    "concB = 20.\n",
    "k1 = 6.\n",
    "k2 = 1.0\n",
    "k3 = 230.\n",
    "k4 = 1000.\n",
    "vol = 8.\n",
    "\n",
    "smodel.setModelParameters(concA, concB, k1, k2, k3, k4, vol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data parameters\n",
    "domain = [0, 500]\n",
    "dt = 0.0001\n",
    "stride = 1\n",
    "timesteps = 2\n",
    "data_size = 2560\n",
    "data_multiplier = 1\n",
    "out_resolution = 50\n",
    "\n",
    "smodel.setDataParameters(domain[0], domain[1], dt, stride, timesteps, data_size, data_multiplier, out_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation setup\n",
    "tstride = 1 # For feeding data into algorithm   \n",
    "\n",
    "# network settings\n",
    "WIDTH = 40 #50 #40 #50 #40 #20 #15 #35 #20              # number of neurons per hidden layer\n",
    "DEPTH = 15 #25 #15 #30 #15 #10 #10 #10 #6               # number of hidden layers\n",
    "ACTIVATION = tf.nn.relu #tf.sigmoid #hidden layer activation function\n",
    "\n",
    "# training settings\n",
    "INIT_L_RATE  = 1e-4 #2e-1\n",
    "FINAL_L_RATE = 1e-5 #1e-3\n",
    "batch_size   = 128 #64 #2048\n",
    "num_batches = int(data_size*data_multiplier/batch_size)\n",
    "num_epochs = 200\n",
    "\n",
    "# Other\n",
    "outscale = (domain[1] - domain[0])/out_resolution\n",
    "filename = \"data/schlogl_data_vol\" + str(vol) + \"_ndata\" + str(data_size) + \".dat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate network structure\n",
    "\n",
    "# Inputs and targets placeholders for trained data\n",
    "networkInput = tf.placeholder(dtype=tf.float32, shape=(None,2), name='input')\n",
    "networkTarget = tf.placeholder(dtype=tf.float32, shape=(None, out_resolution), name='target')\n",
    "\n",
    "# Hidden layers\n",
    "hidden = (DEPTH-1)*[None]\n",
    "hidden[0] = networkInput\n",
    "#next_layer = networkInput\n",
    "for l in range(DEPTH-2):\n",
    "    #without skip connections\n",
    "    hidden[l+1] = tf.layers.dense(hidden[l], WIDTH, activation=ACTIVATION)\n",
    "    \n",
    "# Add predition outermost layer\n",
    "networkPrediction = tf.layers.dense(hidden[DEPTH-2], out_resolution, activation=None, name='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training procedure\n",
    "\n",
    "# Define loss function and error\n",
    "loss = tf.reduce_mean(tf.square(networkPrediction - networkTarget))\n",
    "error = tf.reduce_max(tf.abs(networkPrediction - networkTarget))\n",
    "\n",
    "# use stochastic gradient descent with ADAM during optimization\n",
    "step = tf.train.AdamOptimizer(INIT_L_RATE).minimize(loss)\n",
    "\n",
    "# # Or use decaying learning rate with SGD\n",
    "# NUM_ITER = num_batches*batch_size*num_epochs\n",
    "# global_step = tf.Variable(0, trainable=False)\n",
    "# learning_rate = tf.train.exponential_decay(\n",
    "#     INIT_L_RATE,\n",
    "#     global_step,\n",
    "#     1,\n",
    "#     np.exp(np.log(FINAL_L_RATE/INIT_L_RATE) / NUM_ITER),\n",
    "#     staircase=True\n",
    "# )\n",
    "# step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all parameters\n",
    "print('\\n----------------------------------------------------') \n",
    "print(' RUNNING EXPERIMENT WITH THE FOLLOWING PARAMETERS: ')\n",
    "print('----------------------------------------------------\\n')\n",
    "print('depth:\\t\\t\\t{}'.format(DEPTH))\n",
    "print('width:\\t\\t\\t{}'.format(WIDTH))\n",
    "print('number of neurons:\\t{}'.format(2+(DEPTH-2)*WIDTH))\n",
    "print('number of connections:\\t{}'.format(1+(DEPTH-2)*WIDTH*2+WIDTH*WIDTH*(DEPTH-3)*(DEPTH-2)//2))\n",
    "print('activation:\\t\\t{}'.format(ACTIVATION.__name__))\n",
    "print('learning rate:\\t\\t{} to {}'.format(INIT_L_RATE, FINAL_L_RATE))\n",
    "print('epochs: \\t\\t{}'.format(num_epochs))\n",
    "print('batch size:\\t\\t{}'.format(batch_size))\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate and/or load data\n",
    "generateData = False\n",
    "if generateData:\n",
    "    smodel.generateData()\n",
    "inputData, targetData = smodel.loadData(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Tensorflow session and initialize all network variables\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training\n",
    "\n",
    "# run gradient descent steps with Adam\n",
    "print('\\nStarted training...')\n",
    "print('{:8s}\\t{:8s}\\t{:8s}\\t{:8s}'.format('Epoch', 'Iteration', 'l2-loss', 'linf-err'))\n",
    "print('{:8s}\\t{:8s}\\t{:8s}\\t{:8s}'.format(*(4*[8*'-'])))\n",
    "for epoch in range(num_epochs):\n",
    "    # generate random batch of inputs and corresponding target values\n",
    "    indicesList = np.random.choice(data_size*data_multiplier, [num_batches, batch_size], replace = False)\n",
    "    # Loop over all possible batches within the dataset\n",
    "    for jbatch in range(num_batches):\n",
    "        indices =  (indicesList[jbatch]).astype(int)\n",
    "        inputBatch = np.take(inputData, indices, axis=0)\n",
    "        #tstep = np.random.randint(0, int(timesteps/tstride), batch_size) #dt*j*tstride*np.ones(len(inputx))\n",
    "        #time = tstep #dt*tstep*tstride\n",
    "        #inputBatch = np.reshape(np.column_stack((inputx,time)), [-1,2])\n",
    "        #inputBatch = np.reshape(inputx, [-1,1])\n",
    "        \n",
    "        #currentStepsData = np.take(targetData, tstep, axis=0)\n",
    "        #matrix = np.take(currentStepsData, indices, axis = 1)\n",
    "        #targetBatch = np.diagonal(matrix, axis1 = 0, axis2 = 1).transpose()\n",
    "        #targetBatch = terminalCondition(inputx)\n",
    "        targetBatch = np.take(np.array(targetData), indices, axis = 0)\n",
    "        \n",
    "        \n",
    "        # take gradient descent step and compute loss & error\n",
    "        loss_val, error_val, _ = session.run(\n",
    "            [loss, error, step],\n",
    "            feed_dict={networkInput: inputBatch, networkTarget: targetBatch}\n",
    "        )\n",
    "#         # Loop over all timesteps used for training\n",
    "#         for tstep in range(int(timesteps/tstride)):\n",
    "#             time = tstep*np.ones(batch_size) #dt*tstep*tstride*np.ones(BATCH_SIZE)\n",
    "#             inputBatch = np.reshape(np.column_stack((inputx,time)), [-1,2])\n",
    "#             targetBatch = np.take(np.array(targetData[tstep]), indices, axis = 0)\n",
    "\n",
    "#             # take gradient descent step and compute loss & error\n",
    "#             loss_val, error_val, _ = session.run(\n",
    "#                 [loss, error, step],\n",
    "#                 feed_dict={networkInput: inputBatch, networkTarget: targetBatch}\n",
    "#             )\n",
    "        if (epoch*num_batches + jbatch) % 500 == 0:\n",
    "            print('{:8d}\\t{:8d}\\t{:1.5e}\\t{:1.5e}'.format(epoch, epoch*num_batches + jbatch, loss_val, error_val))\n",
    "print('...finished training.\\n')\n",
    "\n",
    "# tstep = np.random.randint(0, int(timesteps/tstride), BATCH_SIZE) #dt*j*tstride*np.ones(len(inputx))\n",
    "# currentStepsData = np.take(targetData, tstep, axis=0)\n",
    "# matrix = np.take(currentStepsData, indices, axis = 1)\n",
    "# targetBatch = np.diagonal(matrix, axis1 = 0, axis2 = 1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for vector case\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (11,8)\n",
    "# generate full sample grid of input domain\n",
    "RESOLUTION = 500\n",
    "xgrid = np.linspace(domain[0] + 1, domain[1], num=RESOLUTION)\n",
    "#xgrid = xgrid.astype(int)\n",
    "time = 0*np.ones(len(xgrid))\n",
    "input_test_batch = np.reshape(np.column_stack((xgrid,time)) , [-1,2])\n",
    "#input_test_batch = np.reshape(xgrid, [-1,1])\n",
    "\n",
    "\n",
    "# get model predictions\n",
    "prediction_test_batch = session.run( networkPrediction, feed_dict={networkInput: input_test_batch})\n",
    "\n",
    "# Remove negative entries and renormalize\n",
    "x0index = 50\n",
    "#renormalized_output = np.mean(prediction_test_batch, axis=0)\n",
    "renormalized_output = prediction_test_batch[x0index]\n",
    "renormalized_output[renormalized_output<0] = 0.0\n",
    "renormalized_output = renormalized_output/np.sum(renormalized_output)\n",
    "\n",
    "# # Calculate steady state analytically\n",
    "# n=np.linspace(domain[0], (domain[1]-domain[0])-1, domain[1]-domain[0])\n",
    "# ss_solution=np.zeros(len(n))\n",
    "# for i in range(len(n)):\n",
    "#     ss_solution[i] = smodel.steadystate_solution(i)\n",
    "\n",
    "# ss_solution = ss_solution/np.sum(ss_solution) \n",
    "\n",
    "# plot resultiung histogram\n",
    "#plt.bar(np.arange(OUTPUT_RES),np.mean(prediction_test_batch, axis=0))\n",
    "plt.bar(np.arange(outscale/2,outscale*out_resolution,outscale),renormalized_output/outscale, \n",
    "        width=outscale, label=\"NN\", color=(0.0, 0.4, 1.0, 0.5))\n",
    "\n",
    "#Plot analytic solution\n",
    "# plt.plot(n,ss_solution, '-r', lw = 3, label=\"Steady state (exact)\")\n",
    "#plt.plot(n,np.log(ss_solution))\n",
    "\n",
    "#plt.ylim([0.0,0.05])\n",
    "#plt.xlim([0, outscale*OUTPUT_RES])\n",
    "plt.xlim([0, 400])\n",
    "#plt.ylim([0.0,0.02])\n",
    "\n",
    "\n",
    "plt.ylabel('Probability', fontsize = 35)\n",
    "plt.xlabel('$X[T]$', fontsize = 35)\n",
    "plt.legend(fontsize = 35)\n",
    "plt.tick_params(labelsize=30)\n",
    "plt.locator_params(axis='y', nbins=6)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netInput = np.reshape(np.column_stack((240,0)) , [-1,2]) \n",
    "prediction = session.run( networkPrediction, feed_dict={networkInput: netInput})\n",
    "plt.bar(np.arange(OUTPUT_RES),prediction[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interactive_output(x,t):\n",
    "    netInput = np.reshape(np.column_stack((x,t)) , [-1,2]) \n",
    "    prediction = session.run( networkPrediction, feed_dict={networkInput: netInput})\n",
    "    # Remove negative entries and renormalize\n",
    "    #renormalized_output = np.mean(prediction_test_batch, axis=0)\n",
    "    prediction[prediction<0] = 0.0\n",
    "    prediction = prediction/np.sum(prediction)\n",
    "\n",
    "    plt.bar(np.arange(1,outscale*OUTPUT_RES,outscale),prediction[0]/outscale, width=outscale)\n",
    "    plt.plot(n,ss_solution, '-r')\n",
    "    plt.xlim([DOMAIN[0], DOMAIN[1]-100])\n",
    "    plt.ylim([0, 0.05])\n",
    "    plt.ylabel('Histogram')\n",
    "    plt.show()\n",
    "\n",
    "interactive_plot = interactive(interactive_output, x=(DOMAIN[0],DOMAIN[1]-100,10), t=(0,100,10))\n",
    "output = interactive_plot.children[-1]\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([None]*int(timesteps/tstride))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(targetData, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 20\n",
    "A = 1\n",
    "B = 1\n",
    "kk1 = 3*x0\n",
    "kk2 = 1.0\n",
    "kk3 = x0**3 - 200*x0\n",
    "kk4 = (3*x0**2-200)\n",
    "xmax = 100\n",
    "res = 200\n",
    "xx = np.linspace(-xmax,xmax,res)\n",
    "y = ODE_func(xx,kk1,kk2,kk3,kk4,A,B)\n",
    "plt.plot(xx,y)\n",
    "plt.ylim([-5000,5000])\n",
    "plt.xlim([0,50])\n",
    "plt.plot(xx,0*y,'--k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kk1,kk2,kk3,kk4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4000/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 15\n",
    "A = 10\n",
    "B = 20\n",
    "kk1 = 6\n",
    "kk2 = 1.0\n",
    "kk3 = 250\n",
    "kk4 = 1000\n",
    "xmax = 100\n",
    "res = 200\n",
    "xx = np.linspace(-xmax,xmax,res)\n",
    "y = ODE_func(xx,kk1,kk2,kk3,kk4,A,B)\n",
    "plt.plot(xx,y)\n",
    "plt.ylim([-5000,5000])\n",
    "plt.xlim([0,50])\n",
    "plt.plot(xx,0*y,'--k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1875/75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kk1,kk2,kk3,kk4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmax = 100\n",
    "x0 = 50.0\n",
    "xx = np.linspace(-xmax,xmax,res)\n",
    "plt.ylim([-5000,5000])\n",
    "plt.plot(xx,-(xx-x0)**3+(xx-x0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numReactions1 = np.random.poisson(lambda1(20)*dt, 1)\n",
    "numReactions2 = np.random.poisson(lambda2(20)*dt, 1)\n",
    "numReactions3 = np.random.poisson(lambda3(20)*dt, 1)\n",
    "numReactions4 = np.random.poisson(lambda4(20)*dt, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numReactions1, numReactions2, numReactions3, numReactions4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=np.linspace(0,199,200)\n",
    "ss_solution=np.zeros(200)\n",
    "for i in range(200):\n",
    "    ss_solution[i] = steadystate_solution(i)\n",
    "\n",
    "ss_solution = ss_solution/np.sum(ss_solution) \n",
    "plt.xlim([0,200])\n",
    "#plt.plot(n,np.log(ss_solution))\n",
    "plt.plot(n,ss_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = OUTPUT_RES\n",
    "plt.bar(np.arange(N)*outscale,np.mean(targetData,axis=0),width=outscale)\n",
    "# Calculate steady state analytically\n",
    "n=np.linspace(DOMAIN[0], (DOMAIN[1]-DOMAIN[0])-1, N)\n",
    "ss_solution=np.zeros(N)\n",
    "for i in range(N):\n",
    "    ss_solution[i] = steadystate_solution(int(n[i]))\n",
    "\n",
    "ss_solution = ss_solution/np.sum(ss_solution) \n",
    "plt.plot(n,ss_solution, '-r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "concA = 1\n",
    "concB = 2\n",
    "k1 = 3.0\n",
    "k2 = 0.6\n",
    "k3 = 0.25\n",
    "k4 = 2.95\n",
    "vol = 30 #100.0\n",
    "def func(x):\n",
    "    return k1*concA*x**2 - k2*x**3 -k4*x + k3*concB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,50,500)\n",
    "plt.plot(x,func(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=np.float32(np.random.randint( DOMAIN[0], DOMAIN[1], datasize ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
