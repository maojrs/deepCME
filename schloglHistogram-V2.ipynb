{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "# concA = 1\n",
    "# concB = 2\n",
    "# k1 = 3.0\n",
    "# k2 = 0.6\n",
    "# k3 = 0.25\n",
    "# k4 = 2.95\n",
    "# vol = 30 #100.0\n",
    "\n",
    "concA = 10\n",
    "concB = 20\n",
    "k1 = 6\n",
    "k2 = 1.0\n",
    "k3 = 230\n",
    "k4 = 1000\n",
    "vol = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation setup\n",
    "timesteps = 10\n",
    "tstride = 1\n",
    "dt = 0.0001 #0.1\n",
    "\n",
    "# Network setup\n",
    "DOMAIN = [0, 500]   \n",
    "\n",
    "# network settings\n",
    "WIDTH = 40 #50 #40 #20 #15 #35 #20              # number of neurons per hidden layer\n",
    "DEPTH = 15 #30 #15 #10 #10 #10 #6               # number of hidden layers\n",
    "ACTIVATION = tf.nn.relu #tf.sigmoid #hidden layer activation function\n",
    "\n",
    "# training settings\n",
    "INIT_L_RATE  = 1e-3 #2e-1\n",
    "FINAL_L_RATE = 1e-5 #1e-3\n",
    "batch_size   = 64 #2048\n",
    "data_size = 2560 #10240\n",
    "data_multiplier = 5\n",
    "num_batches = int(data_size*data_multiplier/batch_size)\n",
    "num_epochs = 200\n",
    "\n",
    "# Other\n",
    "OUTPUT_RES = 50 #125\n",
    "outscale = (DOMAIN[1] - DOMAIN[0])/OUTPUT_RES\n",
    "FILENAME = \"data/schlogl_data_v\" + str(vol) + \"_\" + str(data_size) + \".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CME birth/death rates\n",
    "def lambdan(n):\n",
    "    return concA*k1*n*(n-1)/vol + concB*k3*vol\n",
    "def mun(n):\n",
    "    return k2*n*(n-1)*(n-2)/vol**2 + n*k4\n",
    "\n",
    "# Define intensity functions for tau-leaping\n",
    "def lambda1(n):\n",
    "    return concA*k1*n*(n-1)/vol\n",
    "def lambda2(n):\n",
    "    return k2*n*(n-1)*(n-2)/vol**2\n",
    "def lambda3(n):\n",
    "    return concB*k3*vol\n",
    "def lambda4(n):\n",
    "    return  n*k4\n",
    "\n",
    "def ODE_func(x,k1,k2,k3,k4,a,b):\n",
    "    return k1*a*x**2 - k2*x**3- k4*x + k3*b\n",
    "\n",
    "def steadystate_solution(n):\n",
    "    result = 1.0\n",
    "    for i in range(n):\n",
    "        result = result*(lambdan(i)/mun(i+1))\n",
    "    return result\n",
    "    \n",
    "def terminalCondition(n):\n",
    "    hist = np.linspace(DOMAIN[0], DOMAIN[1], OUTPUT_RES)\n",
    "    dx = hist[1] - hist[0]\n",
    "    #result = []\n",
    "    for i in range(len(n)):\n",
    "        index = np.where((n[i] >= hist) & (n[i] < hist + dx ))[0][0]\n",
    "        iresult = np.zeros(OUTPUT_RES)\n",
    "        iresult[index] = 1.0\n",
    "#         if index == 0:\n",
    "#             iresult[index] = 0.9\n",
    "#             iresult[index+1] = 0.1\n",
    "#         elif index == len(n):\n",
    "#             iresult[index-1] = 0.1\n",
    "#             iresult[index] = 0.9\n",
    "#         else:\n",
    "#             iresult[index-1] = 0.1\n",
    "#             iresult[index] = 0.8\n",
    "#             iresult[index+1] = 0.1\n",
    "        #result.append(iresult)\n",
    "    return iresult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate network structure\n",
    "\n",
    "# Inputs and targets placeholders for trained data\n",
    "networkInput = tf.placeholder(dtype=tf.float32, shape=(None,2), name='input')\n",
    "networkTarget = tf.placeholder(dtype=tf.float32, shape=(None, OUTPUT_RES), name='target')\n",
    "\n",
    "# Hidden layers\n",
    "hidden = (DEPTH-1)*[None]\n",
    "hidden[0] = networkInput\n",
    "#next_layer = networkInput\n",
    "for l in range(DEPTH-2):\n",
    "    #without skip connections\n",
    "    hidden[l+1] = tf.layers.dense(hidden[l], WIDTH, activation=ACTIVATION)\n",
    "    \n",
    "# Add predition outermost layer\n",
    "networkPrediction = tf.layers.dense(hidden[DEPTH-2], OUTPUT_RES, activation=None, name='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def u(t, x):\n",
    "#     u = networkPrediction(tf.concat([t,x],1), weights, biases)\n",
    "#     return u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training procedure\n",
    "\n",
    "# Define loss function and error\n",
    "loss = tf.reduce_mean(tf.square(networkPrediction - networkTarget))\n",
    "error = tf.reduce_max(tf.abs(networkPrediction - networkTarget))\n",
    "\n",
    "# use stochastic gradient descent with ADAM during optimization\n",
    "step = tf.train.AdamOptimizer(INIT_L_RATE).minimize(loss)\n",
    "\n",
    "# # Or use decaying learning rate with SGD\n",
    "# NUM_ITER = num_batches*batch_size*num_epochs\n",
    "# global_step = tf.Variable(0, trainable=False)\n",
    "# learning_rate = tf.train.exponential_decay(\n",
    "#     INIT_L_RATE,\n",
    "#     global_step,\n",
    "#     1,\n",
    "#     np.exp(np.log(FINAL_L_RATE/INIT_L_RATE) / NUM_ITER),\n",
    "#     staircase=True\n",
    "# )\n",
    "# step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all parameters\n",
    "print('\\n----------------------------------------------------') \n",
    "print(' RUNNING EXPERIMENT WITH THE FOLLOWING PARAMETERS: ')\n",
    "print('----------------------------------------------------\\n')\n",
    "print('depth:\\t\\t\\t{}'.format(DEPTH))\n",
    "print('width:\\t\\t\\t{}'.format(WIDTH))\n",
    "print('number of neurons:\\t{}'.format(2+(DEPTH-2)*WIDTH))\n",
    "print('number of connections:\\t{}'.format(1+(DEPTH-2)*WIDTH*2+WIDTH*WIDTH*(DEPTH-3)*(DEPTH-2)//2))\n",
    "print('activation:\\t\\t{}'.format(ACTIVATION.__name__))\n",
    "print('learning rate:\\t\\t{} to {}'.format(INIT_L_RATE, FINAL_L_RATE))\n",
    "print('epochs:\\t\\t{}'.format(num_epochs))\n",
    "print('batch size:\\t\\t{}'.format(batch_size))\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Input/target data in parallel\n",
    "generatedata = False\n",
    "tfinal = 0.1*1000\n",
    "\n",
    "# Do tau-leap integration loop (only for scalar initial condition)\n",
    "def target_func_one(X0):\n",
    "    N = np.zeros(timesteps)\n",
    "    N[0] = X0\n",
    "    for i in range(timesteps-1):\n",
    "        numReactions1 = np.random.poisson(lambda1(N[i])*dt, 1)\n",
    "        numReactions2 = np.random.poisson(lambda2(N[i])*dt, 1)\n",
    "        numReactions3 = np.random.poisson(lambda3(N[i])*dt, 1)\n",
    "        numReactions4 = np.random.poisson(lambda4(N[i])*dt, 1)\n",
    "        N[i+1] = N[i] + numReactions1 - numReactions2 + numReactions3 - numReactions4\n",
    "        if N[i+1] < 0:\n",
    "            N[i+1] = 0\n",
    "    return N\n",
    "\n",
    "def gillespie(X0):\n",
    "    N = np.zeros(1)\n",
    "    N[0] = X0\n",
    "    t = 0.0\n",
    "    i = 0\n",
    "    while t <= tfinal:\n",
    "        r1 = np.random.rand()\n",
    "        r2 = np.random.rand()\n",
    "        rates = [lambda1(N[i]), lambda2(N[i]), lambda3(N[i]), lambda4(N[i])]\n",
    "        lambda0 = np.sum(rates)\n",
    "        ratescumsum = np.cumsum(rates)\n",
    "        # Gillespie, time and transition\n",
    "        lagtime = np.log(1.0/r1)/lambda0\n",
    "        state = int(sum(r2*lambda0>ratescumsum)) + 1\n",
    "        if state == 1 or state == 3:\n",
    "            nextN = N[i] + 1\n",
    "            N = np.append(N, nextN)\n",
    "        else: # state == 2 or state == 4:\n",
    "            nextN = N[i] - 1\n",
    "            N = np.append(N, nextN)\n",
    "        t = t + lagtime\n",
    "        i = i + 1\n",
    "        print(len(N))\n",
    "    return N\n",
    "\n",
    "\n",
    "stride = 10\n",
    "x0 = np.float32(np.random.randint( DOMAIN[0], DOMAIN[1], data_size ))\n",
    "def propagate(x):\n",
    "    xt = np.float32(target_func_one(x))\n",
    "    y0 = np.zeros(int(timesteps/stride))\n",
    "    #xt = np.float32(gillespie(x))\n",
    "    #y0 = np.zeros(int(len(xt)/stride))\n",
    "    for j in range(len(y0)):\n",
    "        y0[j] = 1.0*xt[j*stride]\n",
    "    return y0\n",
    "    \n",
    "if generatedata:  \n",
    "    num_cores = multiprocessing.cpu_count() \n",
    "    results = Parallel(n_jobs=num_cores, verbose = 2)(delayed(propagate)(i) for i in x0)\n",
    "    print(\"Writing to file ...\", end=\"\\r\")\n",
    "    f = open(FILENAME,\"w\")\n",
    "    for i in range(len(results)):\n",
    "        f.write(\" \".join(str(x) for x in results[i]) + \"\\n\")\n",
    "    f.close()\n",
    "    print(\"Percentage finished:\", 100, \"%    \", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# readGenerateddata = True\n",
    "# #FILENAME = \"data/schlogl_data_v8_5120.txt\"\n",
    "# targetData = [None]*int(timesteps/tstride)\n",
    "# if readGenerateddata:\n",
    "#     data = np.genfromtxt(FILENAME, delimiter=' ')\n",
    "#     inputData = data[:,0]\n",
    "#     for i in range(int(timesteps/tstride)):\n",
    "#         targetData[i] = terminalCondition(data[:,i])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and extend data for time dependent case\n",
    "readGenerateddata = True\n",
    "#targetData = [None]*int(timesteps/tstride)\n",
    "targetData = [None]*(data_size*data_multiplier)\n",
    "if readGenerateddata:\n",
    "    data = np.genfromtxt(FILENAME, delimiter=' ')\n",
    "    inputData = data[:,0]\n",
    "    inputData = np.array([inputData]*data_multiplier).flatten()\n",
    "    tstep = np.random.randint(0, int(timesteps/tstride), data_size*data_multiplier)\n",
    "    inputData = np.reshape(np.column_stack((inputData,tstep)), [-1,2])\n",
    "    for i in range(data_size*data_multiplier):\n",
    "        j = i%data_size\n",
    "        targetData[i] = terminalCondition(np.array([data[j,tstep[i]]]))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tstep = np.random.randint(0, int(timesteps/tstride), batch_size) #dt*j*tstride*np.ones(len(inputx))\n",
    "# currentStepsData = np.take(targetData, tstep, axis=0)\n",
    "# matrix = np.take(currentStepsData, indices, axis = 1)\n",
    "# print(np.array(targetData).shape,currentStepsData.shape,matrix.shape)\n",
    "# indices =  (indicesList[jbatch]).astype(int)\n",
    "# inputBatch = np.take(inputData, indices, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Tensorflow session and initialize all network variables\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training\n",
    "\n",
    "# run gradient descent steps with Adam\n",
    "print('\\nStarted training...')\n",
    "print('{:8s}\\t{:8s}\\t{:8s}\\t{:8s}'.format('Epoch', 'Iteration', 'l2-loss', 'linf-err'))\n",
    "print('{:8s}\\t{:8s}\\t{:8s}\\t{:8s}'.format(*(4*[8*'-'])))\n",
    "for epoch in range(num_epochs):\n",
    "    # generate random batch of inputs and corresponding target values\n",
    "    indicesList = np.random.choice(data_size*data_multiplier, [num_batches, batch_size], replace = False)\n",
    "    # Loop over all possible batches within the dataset\n",
    "    for jbatch in range(num_batches):\n",
    "        indices =  (indicesList[jbatch]).astype(int)\n",
    "        inputBatch = np.take(inputData, indices, axis=0)\n",
    "        #tstep = np.random.randint(0, int(timesteps/tstride), batch_size) #dt*j*tstride*np.ones(len(inputx))\n",
    "        #time = tstep #dt*tstep*tstride\n",
    "        #inputBatch = np.reshape(np.column_stack((inputx,time)), [-1,2])\n",
    "        #inputBatch = np.reshape(inputx, [-1,1])\n",
    "        \n",
    "        #currentStepsData = np.take(targetData, tstep, axis=0)\n",
    "        #matrix = np.take(currentStepsData, indices, axis = 1)\n",
    "        #targetBatch = np.diagonal(matrix, axis1 = 0, axis2 = 1).transpose()\n",
    "        #targetBatch = terminalCondition(inputx)\n",
    "        targetBatch = np.take(np.array(targetData), indices, axis = 0)\n",
    "        \n",
    "        \n",
    "        # take gradient descent step and compute loss & error\n",
    "        loss_val, error_val, _ = session.run(\n",
    "            [loss, error, step],\n",
    "            feed_dict={networkInput: inputBatch, networkTarget: targetBatch}\n",
    "        )\n",
    "#         # Loop over all timesteps used for training\n",
    "#         for tstep in range(int(timesteps/tstride)):\n",
    "#             time = tstep*np.ones(batch_size) #dt*tstep*tstride*np.ones(BATCH_SIZE)\n",
    "#             inputBatch = np.reshape(np.column_stack((inputx,time)), [-1,2])\n",
    "#             targetBatch = np.take(np.array(targetData[tstep]), indices, axis = 0)\n",
    "\n",
    "#             # take gradient descent step and compute loss & error\n",
    "#             loss_val, error_val, _ = session.run(\n",
    "#                 [loss, error, step],\n",
    "#                 feed_dict={networkInput: inputBatch, networkTarget: targetBatch}\n",
    "#             )\n",
    "        if (epoch*num_batches + jbatch) % 500 == 0:\n",
    "            print('{:8d}\\t{:8d}\\t{:1.2e}\\t{:1.2e}'.format(epoch, epoch*num_batches + jbatch, loss_val, error_val))\n",
    "print('...finished training.\\n')\n",
    "\n",
    "# tstep = np.random.randint(0, int(timesteps/tstride), BATCH_SIZE) #dt*j*tstride*np.ones(len(inputx))\n",
    "# currentStepsData = np.take(targetData, tstep, axis=0)\n",
    "# matrix = np.take(currentStepsData, indices, axis = 1)\n",
    "# targetBatch = np.diagonal(matrix, axis1 = 0, axis2 = 1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for vector case\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (11,8)\n",
    "# generate full sample grid of input domain\n",
    "RESOLUTION = 500\n",
    "xgrid = np.linspace(DOMAIN[0] + 1, DOMAIN[1], num=RESOLUTION)\n",
    "#xgrid = xgrid.astype(int)\n",
    "time = 10.0*np.ones(len(xgrid))\n",
    "input_test_batch = np.reshape(np.column_stack((xgrid,time)) , [-1,2])\n",
    "#input_test_batch = np.reshape(xgrid, [-1,1])\n",
    "\n",
    "\n",
    "# get model predictions\n",
    "prediction_test_batch = session.run( networkPrediction, feed_dict={networkInput: input_test_batch})\n",
    "\n",
    "# Remove negative entries and renormalize\n",
    "x0index = 250\n",
    "#renormalized_output = np.mean(prediction_test_batch, axis=0)\n",
    "renormalized_output = prediction_test_batch[x0index]\n",
    "renormalized_output[renormalized_output<0] = 0.0\n",
    "renormalized_output = renormalized_output/np.sum(renormalized_output)\n",
    "\n",
    "# Calculate steady state analytically\n",
    "n=np.linspace(DOMAIN[0], (DOMAIN[1]-DOMAIN[0])-1, DOMAIN[1]-DOMAIN[0])\n",
    "ss_solution=np.zeros(len(n))\n",
    "for i in range(len(n)):\n",
    "    ss_solution[i] = steadystate_solution(i)\n",
    "\n",
    "ss_solution = ss_solution/np.sum(ss_solution) \n",
    "\n",
    "# plot resultiung histogram\n",
    "#plt.bar(np.arange(OUTPUT_RES),np.mean(prediction_test_batch, axis=0))\n",
    "plt.bar(np.arange(outscale/2,outscale*OUTPUT_RES,outscale),renormalized_output/outscale, \n",
    "        width=outscale, label=\"NN\", color=(0.0, 0.4, 1.0, 0.5))\n",
    "\n",
    "#Plot analytic solution\n",
    "plt.plot(n,ss_solution, '-r', lw = 3, label=\"Steady state (exact)\")\n",
    "#plt.plot(n,np.log(ss_solution))\n",
    "\n",
    "#plt.ylim([0.0,0.05])\n",
    "#plt.xlim([0, outscale*OUTPUT_RES])\n",
    "plt.xlim([0, 400])\n",
    "plt.ylim([0.0,0.02])\n",
    "\n",
    "\n",
    "plt.ylabel('Probability', fontsize = 35)\n",
    "plt.xlabel('$X[T]$', fontsize = 35)\n",
    "plt.legend(fontsize = 35)\n",
    "plt.tick_params(labelsize=30)\n",
    "plt.locator_params(axis='y', nbins=6)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstep = np.random.randint(0, int(timesteps/tstride), BATCH_SIZE)\n",
    "currentStepsData = np.take(targetData, tstep, axis=0)\n",
    "matrix = np.take(currentStepsData, indices, axis = 1)\n",
    "targetBatch = np.diagonal(matrix, axis1 = 0, axis2 = 1).transpose()\n",
    "targetBatch[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Renormalize\n",
    "renormalized_output = 1.0*prediction_test_batch\n",
    "for i in range(RESOLUTION):\n",
    "    out = prediction_test_batch[i]\n",
    "    out[out<0] = 0.0\n",
    "    out = out/np.sum(out)\n",
    "    renormalized_output[i] = 1.0*out\n",
    "    \n",
    "\n",
    "def interactive_output(x):\n",
    "    x0 = np.int(x/outscale)\n",
    "    plt.bar(np.arange(1,outscale*OUTPUT_RES,outscale),renormalized_output[x0]/outscale, width=outscale)\n",
    "    plt.plot(n,ss_solution, '-r')\n",
    "    plt.xlim([DOMAIN[0], DOMAIN[1]])\n",
    "    plt.ylim([0, 0.05])\n",
    "    plt.ylabel('Histogram')\n",
    "    plt.show()\n",
    "\n",
    "interactive_plot = interactive(interactive_output, x=(DOMAIN[0],DOMAIN[1],10))\n",
    "output = interactive_plot.children[-1]\n",
    "interactive_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len([None]*int(timesteps/tstride))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(targetData, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 20\n",
    "A = 1\n",
    "B = 1\n",
    "kk1 = 3*x0\n",
    "kk2 = 1.0\n",
    "kk3 = x0**3 - 200*x0\n",
    "kk4 = (3*x0**2-200)\n",
    "xmax = 100\n",
    "res = 200\n",
    "xx = np.linspace(-xmax,xmax,res)\n",
    "y = ODE_func(xx,kk1,kk2,kk3,kk4,A,B)\n",
    "plt.plot(xx,y)\n",
    "plt.ylim([-5000,5000])\n",
    "plt.xlim([0,50])\n",
    "plt.plot(xx,0*y,'--k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kk1,kk2,kk3,kk4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4000/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = 15\n",
    "A = 10\n",
    "B = 20\n",
    "kk1 = 6\n",
    "kk2 = 1.0\n",
    "kk3 = 250\n",
    "kk4 = 1000\n",
    "xmax = 100\n",
    "res = 200\n",
    "xx = np.linspace(-xmax,xmax,res)\n",
    "y = ODE_func(xx,kk1,kk2,kk3,kk4,A,B)\n",
    "plt.plot(xx,y)\n",
    "plt.ylim([-5000,5000])\n",
    "plt.xlim([0,50])\n",
    "plt.plot(xx,0*y,'--k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1875/75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kk1,kk2,kk3,kk4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmax = 100\n",
    "x0 = 50.0\n",
    "xx = np.linspace(-xmax,xmax,res)\n",
    "plt.ylim([-5000,5000])\n",
    "plt.plot(xx,-(xx-x0)**3+(xx-x0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numReactions1 = np.random.poisson(lambda1(20)*dt, 1)\n",
    "numReactions2 = np.random.poisson(lambda2(20)*dt, 1)\n",
    "numReactions3 = np.random.poisson(lambda3(20)*dt, 1)\n",
    "numReactions4 = np.random.poisson(lambda4(20)*dt, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numReactions1, numReactions2, numReactions3, numReactions4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_test_batch[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=np.linspace(0,199,200)\n",
    "ss_solution=np.zeros(200)\n",
    "for i in range(200):\n",
    "    ss_solution[i] = steadystate_solution(i)\n",
    "\n",
    "ss_solution = ss_solution/np.sum(ss_solution) \n",
    "plt.xlim([0,200])\n",
    "#plt.plot(n,np.log(ss_solution))\n",
    "plt.plot(n,ss_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = OUTPUT_RES\n",
    "plt.bar(np.arange(N)*outscale,np.mean(targetData,axis=0),width=outscale)\n",
    "# Calculate steady state analytically\n",
    "n=np.linspace(DOMAIN[0], (DOMAIN[1]-DOMAIN[0])-1, N)\n",
    "ss_solution=np.zeros(N)\n",
    "for i in range(N):\n",
    "    ss_solution[i] = steadystate_solution(int(n[i]))\n",
    "\n",
    "ss_solution = ss_solution/np.sum(ss_solution) \n",
    "plt.plot(n,ss_solution, '-r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "concA = 1\n",
    "concB = 2\n",
    "k1 = 3.0\n",
    "k2 = 0.6\n",
    "k3 = 0.25\n",
    "k4 = 2.95\n",
    "vol = 30 #100.0\n",
    "def func(x):\n",
    "    return k1*concA*x**2 - k2*x**3 -k4*x + k3*concB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0,50,500)\n",
    "plt.plot(x,func(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=np.float32(np.random.randint( DOMAIN[0], DOMAIN[1], datasize ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
