{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For tensorboard\n",
    "from datetime import datetime\n",
    "now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "root_logdir = \"tf_logs\"\n",
    "logdir = \"{}/run-{}/\".format(root_logdir, now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CME and CLE parameters\n",
    "concA = 10\n",
    "concB = 20\n",
    "k1 = 6\n",
    "k2 = 1.0\n",
    "k3 = 230\n",
    "k4 = 1000\n",
    "vol = 32 #30 #18 #8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "dt = 0.001\n",
    "nreactions = 4\n",
    "timesteps = 10000\n",
    "\n",
    "# Network parameters\n",
    "hlayer_depth = 4\n",
    "hlayer_width = 50\n",
    "activation_func = tf.nn.relu \n",
    "initialLearningRate = 1e-2 #1e-3 \n",
    "trainingIterations = 4000 \n",
    "batchSize   = 64 #512\n",
    "\n",
    "# Domain parameters\n",
    "domain = [0,2000] #[0,1500]\n",
    "outputResolution = 50\n",
    "outscale = (domain[1] - domain[0])/outputResolution\n",
    "\n",
    "# File writing parameters\n",
    "datasize = 4160 #1024*5\n",
    "stride = 10\n",
    "filename = \"data/schloglCLE_v\" + str(vol) + \"_\" + \"_T=\" + str(timesteps*dt) + str(datasize) + \".txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define CME birth/death rates\n",
    "def lambdan(n):\n",
    "    return concA*k1*n*(n-1)/vol + concB*k3*vol\n",
    "def mun(n):\n",
    "    return k2*n*(n-1)*(n-2)/vol**2 + n*k4\n",
    "\n",
    "# Define intensity functions\n",
    "def lambda1(n):\n",
    "    return concA*k1*n*(n-1)/vol\n",
    "def lambda2(n):\n",
    "    return k2*n*(n-1)*(n-2)/vol**2\n",
    "def lambda3(n):\n",
    "    return concB*k3*vol\n",
    "def lambda4(n):\n",
    "    return  n*k4\n",
    "\n",
    "# # Define terminal condition function\n",
    "# def terminalCondition(n):\n",
    "#     return 1.0*n\n",
    "\n",
    "def terminalCondition(n):\n",
    "    hist = np.linspace(domain[0], domain[1], outputResolution)\n",
    "    dx = hist[1] - hist[0]\n",
    "    for i in range(len(n)):\n",
    "        index = np.where((n[i] >= hist) & (n[i] < hist + dx ))[0][0]\n",
    "        iresult = np.zeros(outputResolution)\n",
    "        if index == 0:\n",
    "            iresult[index] = 0.9\n",
    "            iresult[index+1] = 0.1\n",
    "        elif index == len(n):\n",
    "            iresult[index-1] = 0.1\n",
    "            iresult[index] = 0.9\n",
    "        else:\n",
    "            iresult[index-1] = 0.1\n",
    "            iresult[index] = 0.8\n",
    "            iresult[index+1] = 0.1\n",
    "    return iresult\n",
    "\n",
    "def steadystate_solution(n):\n",
    "    result = 1.0\n",
    "    for i in range(n):\n",
    "        result = result*(lambdan(i)/mun(i+1))\n",
    "    return result\n",
    "\n",
    "# Define drift and diffusion coefficients\n",
    "def drift(x):\n",
    "    return lambda1(x) - lambda2(x) + lambda3(x) - lambda4(x)\n",
    "\n",
    "def diffusion(x):\n",
    "    for i in range(len(x)):\n",
    "        sigma = [np.sqrt(lambda1(x[i])), - np.sqrt(lambda2(x[i])), \n",
    "                 np.sqrt(lambda3(x[i])), -np.sqrt(lambda4(x[i]))]\n",
    "    return np.array(sigma, dtype=np.float32)\n",
    "\n",
    "def diffusiontf(x):\n",
    "    sigma = [np.sqrt(lambda1(x)), - np.sqrt(lambda2(x)), \n",
    "             np.sqrt(lambda3(x)), -np.sqrt(lambda4(x))]\n",
    "    return tf.convert_to_tensor(sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Brownian paths function\n",
    "def generateBrownian(n):\n",
    "    output = np.zeros([n,4])\n",
    "    for i in range(n):\n",
    "        output[i] = np.random.normal(0., np.sqrt(dt), nreactions)\n",
    "    return output\n",
    "\n",
    "# Propagate forward SDE function\n",
    "def propagateSDE(x0, brownianPath):\n",
    "    n = len(brownianPath)\n",
    "    dimension = len(x0)\n",
    "    trajectory = np.zeros([n, dimension])\n",
    "    trajectory[0] = 1.0*x0\n",
    "    for i in range(n-1):\n",
    "        x = trajectory[i]\n",
    "        trajectory[i+1] = x + drift(x)*dt + np.dot(diffusion(x),brownianPath[i])\n",
    "        if trajectory[i+1] < 0:\n",
    "            trajectory[i+1] = 0\n",
    "    return trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate network structure\n",
    "\n",
    "# Inputs and targets placeholders for trained data\n",
    "networkInput = tf.placeholder(dtype=tf.float32, shape=(None,1), name='input')\n",
    "networkTarget = tf.placeholder(dtype=tf.float32, shape=(None, outputResolution), name='target')\n",
    "\n",
    "# Hidden layers\n",
    "hidden = (hlayer_depth-1)*[None]\n",
    "hidden[0] = networkInput\n",
    "for l in range(hlayer_depth-2):\n",
    "    hidden[l+1] = tf.layers.dense(hidden[l], hlayer_width, activation=activation_func)\n",
    "    \n",
    "# Add predition outermost layer\n",
    "networkPrediction = tf.layers.dense(hidden[hlayer_depth-2], outputResolution, activation=None, name='prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training procedure\n",
    "\n",
    "# Define loss function and error\n",
    "loss = tf.reduce_mean(tf.square(networkPrediction - networkTarget))\n",
    "error = tf.reduce_max(tf.abs(networkPrediction - networkTarget))\n",
    "\n",
    "# use stochastic gradient descent with ADAM during optimization\n",
    "step = tf.train.AdamOptimizer(initialLearningRate).minimize(loss)\n",
    "\n",
    "# For tensor board\n",
    "mse_summary = tf.summary.scalar('Error', error)\n",
    "file_writer = tf.summary.FileWriter(logdir,\ttf.get_default_graph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Training data\n",
    "generateData = True\n",
    "    \n",
    "if generateData:\n",
    "    x0 = np.float32(np.random.randint(domain[0] + 50, domain[1] - 100, datasize ))    \n",
    "    num_cores = multiprocessing.cpu_count() \n",
    "    brownianTrajs = Parallel(n_jobs=num_cores, \n",
    "                             verbose = 2)(delayed(generateBrownian)(timesteps) for i in range(datasize))\n",
    "    solutionsSDE = Parallel(n_jobs=num_cores, \n",
    "                            verbose = 2)(delayed(propagateSDE)(np.array([x0[i]]),brownianTrajs[i]) for i in range(datasize))\n",
    "    # No need to write to file\n",
    "    #print(\"Writing to file ...\", end=\"\\r\")\n",
    "    #f = open(filename,\"w\")\n",
    "    #for i in range(len(results)):\n",
    "    #    f.write(\" \".join(str(x) for x in results[i]) + \"\\n\")\n",
    "    #f.close()\n",
    "    #print(\"Percentage finished:\", 100, \"%    \", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and target data\n",
    "inputData = [None]*datasize\n",
    "targetData = [None]*datasize\n",
    "for i in range(datasize):\n",
    "    inputData[i] = solutionsSDE[i][0]\n",
    "    targetData[i] = terminalCondition(solutionsSDE[i][-1])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Tensorflow session and initialize all network variables\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the training\n",
    "\n",
    "# run gradient descent steps with Adam\n",
    "print('\\nStarted training...')\n",
    "print('{:8s}\\t{:8s}\\t{:8s}'.format('iter', 'l2-loss', 'linf-err'))\n",
    "print('{:8s}\\t{:8s}\\t{:8s}'.format(*(3*[8*'-'])))\n",
    "for iter in range(trainingIterations):\n",
    "    # generate random batch of inputs and corresponding target values\n",
    "    indices =  np.random.randint(0, datasize, batchSize)\n",
    "    inputBatch = np.reshape(np.take( inputData, indices), [-1,1])\n",
    "    targetBatch = np.take(np.array(targetData), indices, axis = 0)\n",
    "\n",
    "    # take gradient descent step and compute loss & error\n",
    "    loss_val, error_val, _ = session.run(\n",
    "        [loss, error, step],\n",
    "        feed_dict={networkInput: inputBatch, \n",
    "                   networkTarget: targetBatch}\n",
    "    )\n",
    "    if iter % 100 == 0:\n",
    "        print('{:8d}\\t{:1.2e}\\t{:1.2e}'.format(iter, loss_val, error_val))\n",
    "print('...finished training.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate steady state analytically\n",
    "n=np.linspace(domain[0], (domain[1]-domain[0])-1, domain[1]-domain[0])\n",
    "ss_solution=np.zeros(len(n))\n",
    "for i in range(len(n)):\n",
    "    ss_solution[i] = steadystate_solution(i)\n",
    "\n",
    "ss_solution = ss_solution/np.sum(ss_solution) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for vector case\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (11,8)\n",
    "# generate full sample grid of input domain\n",
    "RESOLUTION = domain[1] - domain[0]\n",
    "xgrid = np.linspace(domain[0], domain[1], num=RESOLUTION)\n",
    "xgrid = xgrid.astype(int)\n",
    "input_test_batch = np.reshape(xgrid , [-1,1])\n",
    "\n",
    "# get model predictions\n",
    "prediction_test_batch = session.run( networkPrediction, feed_dict={networkInput: input_test_batch})\n",
    "\n",
    "# Remove negative entries and renormalize\n",
    "x0 = 400\n",
    "#renormalized_output = np.mean(prediction_test_batch, axis=0)\n",
    "renormalized_output = prediction_test_batch[x0]\n",
    "renormalized_output[renormalized_output<0] = 0.0\n",
    "renormalized_output = renormalized_output/np.sum(renormalized_output)\n",
    "\n",
    "# plot resultiung histogram\n",
    "#plt.bar(np.arange(OUTPUT_RES),np.mean(prediction_test_batch, axis=0))\n",
    "plt.bar(np.arange(outscale/2,outscale*outputResolution,outscale),renormalized_output/outscale, \n",
    "        width=outscale, label=\"NN (CLE)\", color=(0.0, 0.4, 1.0, 0.5))\n",
    "\n",
    "#Plot analytic solution\n",
    "plt.plot(n,ss_solution, '-r', lw = 3, label=\"Steady state (exact)\")\n",
    "\n",
    "#plt.ylim([0.0,0.05])\n",
    "#plt.xlim([0, outscale*OUTPUT_RES])\n",
    "#plt.xlim([0, 400])\n",
    "#plt.ylim([0.0,0.02])\n",
    "\n",
    "\n",
    "plt.ylabel('Probability', fontsize = 35)\n",
    "plt.xlabel('$X[T]$', fontsize = 35)\n",
    "#plt.legend(fontsize = 35)\n",
    "plt.tick_params(labelsize=30)\n",
    "plt.locator_params(axis='y', nbins=6)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(ss_solution)\n",
    "np.sum(renormalized_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.mean(targetData,axis=0))\n",
    "plt.plot(n/outscale ,ss_solution*outscale, '-r', lw = 3, label=\"Steady state (exact)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(targetData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
